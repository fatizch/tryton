# number of nginx workers (just asynchronously forwarding)
# only 1 should be enough (2 recommended until we investigate more)
worker_processes 2;

error_log /usr/local/nginx/logs/error.log;

events {
  # number of opened connections per worker (both sides)
  # default limit is 1024 on OS
  # real value 2 x 16 x coog workers number
  # should help to buffering
  worker_connections 128;

  # accept immediately as many connection as it can
  multi_accept on;
}

http {
  access_log /usr/local/nginx/logs/access.log;

  # timeout in seconds (nginx <-> client)
  # depends on heaviest transactions
  send_timeout 600;

  # timeout in seconds (nginx <-> backend)
  # depends on heaviest transactions
  proxy_send_timeout 600;
  proxy_read_timeout 600;

  # avoid waiting to have big pacquets (to avoid protocols overhead)
  # https://t37.net/optimisations-nginx-bien-comprendre-sendfile-tcp-nodelay-et-tcp-nopush.html
  tcp_nodelay on;

  upstream tryton_workers {
    # least_conn is the load balacing method that select a server with
    # the less active(s) connection(s) for the next request.
    least_conn;

    # workers
    server 127.0.0.1:8001;
    server 127.0.0.1:8002;
    server 127.0.0.1:8003;
    server 127.0.0.1:8004;
  }

  server {
    # main entry point url (define url if needed)
    listen 8000;

    # redirection
    location / {
      proxy_pass http://tryton_workers;
    }
  }
}
